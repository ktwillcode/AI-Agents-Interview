# LLM Interview Simulator ğŸ¤–

A fascinating experiment to evaluate how different Large Language Models (LLMs) perform in simulated job interviews. This project creates a controlled environment where multiple LLM models play the role of job candidates while being interviewed by a consistent interviewer model.

![LLM Interview Simulator Demo](demo/interview-simulator-demo.png)
*Interactive interview simulation showing real-time conversation between AI interviewer and candidate*

## ğŸ“‹ Table of Contents
- [Process Flow](#-process-flow)
- [Project Overview](#-project-overview)
- [Models Used](#-models-used)
- [Installation](#-installation)
- [Usage](#-usage)
- [Features](#-features)
- [Project Structure](#-project-structure)
- [Sample Output](#-sample-output)
- [Contributing](#-contributing)
- [License](#-license)
- [Acknowledgments](#-acknowledgments)


## ğŸ”„ Process Flow

### 1. System Setup Flow
```mermaid
flowchart LR
    A[Start] -->|Initialize| B[System Setup]
    B --> C[Load Models]
    B --> D[Configure Job Roles]
    C --> E[Setup Interviewer]
    C --> F[Setup Candidates]
    
    style A fill:#4CAF50,color:white
    style B fill:#2196F3,color:white
    style C fill:#9C27B0,color:white
    style D fill:#FF9800,color:white
    style E fill:#E91E63,color:white
    style F fill:#673AB7,color:white
```

### 2. Interview Process Flow
```mermaid
flowchart LR
    A[Start Interview] -->|Generate| B[Questions]
    B -->|Collect| C[Responses]
    C -->|Analyze| D[Feedback]
    D -->|Next Question| B
    D -->|Complete| E[Evaluation]
    
    style A fill:#4CAF50,color:white
    style B fill:#2196F3,color:white
    style C fill:#9C27B0,color:white
    style D fill:#FF9800,color:white
    style E fill:#E91E63,color:white
```

### 3. Evaluation Flow
```mermaid
flowchart LR
    A[Evaluation] -->|Generate| B[Scores]
    B -->|Identify| C[Strengths]
    B -->|Identify| D[Weaknesses]
    C --> E[Final Report]
    D --> E
    
    style A fill:#4CAF50,color:white
    style B fill:#2196F3,color:white
    style C fill:#9C27B0,color:white
    style D fill:#FF9800,color:white
    style E fill:#E91E63,color:white
```

## ğŸ¯ Project Overview

This project simulates job interviews using different LLM models as candidates, while maintaining a consistent interviewer (Co-founder/CEO) model. The simulation:

- ğŸ“ Conducts structured interviews for various job positions
- ğŸ¤– Uses different LLM models to simulate candidate responses
- ğŸ“Š Provides comprehensive evaluation and feedback
- ğŸ“ˆ Generates comparative analysis across different models
- ğŸ’¡ Offers practical interview improvement suggestions

## ğŸ¤– Models Used

### Interviewer
```python
Model: groq/llama-3.1-8b-instant
Role: Co-founder and CEO
Purpose: Consistent evaluation across all interviews
```

### Candidates
| Model | Type | Purpose |
|-------|------|---------|
| groq/llama-3.1-8b-instant | Base Model | Quick responses |
| groq/llama3-8b-8192 | Enhanced | Detailed analysis |
| groq/mixtral-8x7b-32768 | Advanced | Complex reasoning |
| groq/llama2-70b-4096 | Large-scale | Comprehensive responses |

## ğŸ”§ Installation

1. **Clone the repository:**
```bash
git clone https://github.com/yourusername/llm-interview-simulator.git
cd llm-interview-simulator
```

2. **Create and activate virtual environment:**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies:**
```bash
pip install -r requirements.txt
```

4. **Set up environment variables:**
```bash
echo "GROQ_API_KEY=your_api_key_here" > .env
```

## ğŸ’» Usage

1. **Run the simulation:**
```bash
python main.py
```

2. **Choose a job title:**
```python
job_titles = [
    "Marketing Associate",
    "Business Development Representative",
    "Product Manager",
    "Customer Success Representative",
    "Data Analyst",
    "AI Engineer"
]
```

## ğŸ“Š Features

### Interview Process
- ğŸ”„ Dynamic question generation
- ğŸ’¬ Natural conversation flow
- ğŸ¯ Technical skill assessment
- ğŸ¤ Cultural fit evaluation

### Evaluation Metrics
| Metric | Description |
|--------|-------------|
| Decision | Pass/Fail outcome |
| Score | 0-100 numerical rating |
| Strengths | Key positive attributes |
| Improvements | Areas for development |
| Tips | Interview improvement suggestions |
| Reasoning | Detailed evaluation logic |

## ğŸ“ Project Structure

```
llm-interview-simulator/
â”œâ”€â”€ ğŸ“„ agents.py           # Agent definitions
â”œâ”€â”€ ğŸ“„ tasks.py           # Interview tasks
â”œâ”€â”€ ğŸ“„ interview_simulation.py  # Core logic
â”œâ”€â”€ ğŸ“„ main.py           # Entry point
â”œâ”€â”€ ğŸ“„ requirements.txt  # Dependencies
â””â”€â”€ ğŸ“„ README.md        # Documentation
```

## ğŸ” Sample Output

![Sample Evaluation](demo/sample-evaluation.png)
*Sample evaluation dashboard showing comparative analysis*

### Output Format
```json
{
    "job_title": "AI Engineer",
    "interview_date": "2024-03-31 14:30:22",
    "candidates": {
        "candidate1": {
            "model": "groq/llama-3.1-8b-instant",
            "score": 85,
            "evaluation": "..."
        }
    },
    "comparative_analysis": "..."
}
```

## ğŸ¤ Contributing

We welcome contributions! Areas for improvement:
- ğŸ“ New job positions
- ğŸ¤– Additional LLM models
- ğŸ“Š Enhanced metrics
- ğŸ’¡ Feature additions

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- ğŸ› ï¸ Built with CrewAI framework
- ğŸ¤– Powered by Groq's LLM models
- ğŸ’¼ Inspired by real-world interviews

## âš ï¸ Disclaimer

This is an experimental project for research and educational purposes. The simulations should not be used as the sole basis for actual hiring decisions.

## ğŸ“Š Results Dashboard

![Results Dashboard](demo/results-dashboard.png)
*Interactive dashboard showing model performance comparison*

Key metrics displayed:
- â­ Response quality scores
- ğŸ¤ Cultural fit assessment
- ğŸ§  Technical knowledge evaluation
- ğŸ’¬ Communication style analysis

---
Made with â¤ï¸ by [Your Name]
